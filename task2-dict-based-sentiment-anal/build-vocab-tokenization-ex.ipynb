{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a vocabulary for word tokenization \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My practice here of understand foundational NLP concepts of work tokenizaton to analyse text. Text in this manner is segmented into parts (text) compiled (parsed) from a certain pattern (usually words seperated by whitespace) that generically ignores puncuation besides the word.\n",
    "<br>\n",
    "In this way we build a lexicon (vocabulary) - set of valid words/tokens.\n",
    "<br>\n",
    "***Natural Language Processing In Action (NLPIA) by Lane, Howard and Hapke (2019)*** is what I'm closely following to rehearse this workflow (esp. chp 2.2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence gathered from [Your dictionary](https://sentence.yourdictionary.com/nlp)\n",
    "<br>\n",
    "Example is a rough example relying mostly on built-ins and base scientific libraries (numpy and pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'NLP is a method of examining the way a person thinks and acts through language and using this knowledge to affect change.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['NLP',\n 'is',\n 'a',\n 'method',\n 'of',\n 'examining',\n 'the',\n 'way',\n 'a',\n 'person',\n 'thinks',\n 'and',\n 'acts',\n 'through',\n 'language',\n 'and',\n 'using',\n 'this',\n 'knowledge',\n 'to',\n 'affect',\n 'change.']"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Sentence when tokenized will be split by white space and replaced with commas (delimited) in between\n",
    "sentence.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the only mistake was at then with 'change.' including the puncuation. For developing models eventually, this would be very messy and impractical. Being the first stage of the NLP, it's pretty crucial to do this as accurately as possible. \n",
    "<br>\n",
    "The tokenizer in this way breaks unstructured data (natural language text) into chunks of information that can be represented as meaningful discrete elements.\n",
    "<br>\n",
    "Nevertheless, as a basic/coarse example, we can generally see the process of utilising textual data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be used to create a numerical (one-hot) vector which captures occurences in document text via a sequence of words \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sequence = str.split(sentence) # built-in class method of using split\n",
    "vocab = sorted(set(token_sequence)) # taken distinct set of words and sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['NLP',\n 'a',\n 'acts',\n 'affect',\n 'and',\n 'change.',\n 'examining',\n 'is',\n 'knowledge',\n 'language',\n 'method',\n 'of',\n 'person',\n 'the',\n 'thinks',\n 'this',\n 'through',\n 'to',\n 'using',\n 'way']"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'NLP, a, acts, affect, and, change., examining, is, knowledge, language, method, of, person, the, thinks, this, through, to, using, way'"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Keep in sentence form i.e. remove the list form that split() defaults to as an iterable\n",
    "', '.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(token_sequence)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22\n20\n"
    }
   ],
   "source": [
    "print(num_tokens),\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference of two words because the vocab we created took account repeat - namely 'a' along with 'and'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(22, 20)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# constructing the one-hot (oh) vectors\n",
    "oh_vectors = np.zeros((num_tokens, vocab_size), int)\n",
    "oh_vectors.shape # 22 rows by 20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 NLP\n2 is\n3 a\n4 method\n5 of\n6 examining\n7 the\n8 way\n9 a\n10 person\n11 thinks\n12 and\n13 acts\n14 through\n15 language\n16 and\n17 using\n18 this\n19 knowledge\n20 to\n21 affect\n22 change.\n"
    }
   ],
   "source": [
    "# Tagging index words appears in at such order and the word beside it\n",
    "for i, word in enumerate(token_sequence, start=1):\n",
    "    print(i, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interpreting the oh_vector array:\n",
    "* Rows - index of the words as seen directly above \n",
    "* Columns - distinct set of sorted words as seen in **vocab** variable\n",
    "* Value - where we see '1' is where the word appeared in the vocab (sorted) index from the corresponding (original) tokenized sentence\n",
    "  \n",
    "~~Technical note - this is a type of 'bag of words (BOW)' representation, which is lossless since every unique attribute (token) has its own indicator (index) in the vector/array~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(token_sequence):\n",
    "    oh_vectors[i, vocab.index(word)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'NLP a acts affect and change. examining is knowledge language method of person the thinks this through to using way'"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "' '.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "oh_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example - row 3, the phrase 'a' in the **token_sequence** appears in the index order of 2 in the sorted **vocab** list \n",
    "* Given that it appears twice, it also appears in row 9 as in **token_sequence**, while still maintaining its index order (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this even more clearer, the last step is to turn this array into a DataFrame - enabling us to see such data in a tabulated way where columns have labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    NLP  a  acts  affect  and  change.  examining  is  knowledge  language  \\\n0     1  0     0       0    0        0          0   0          0         0   \n1     0  0     0       0    0        0          0   1          0         0   \n2     0  1     0       0    0        0          0   0          0         0   \n3     0  0     0       0    0        0          0   0          0         0   \n4     0  0     0       0    0        0          0   0          0         0   \n5     0  0     0       0    0        0          1   0          0         0   \n6     0  0     0       0    0        0          0   0          0         0   \n7     0  0     0       0    0        0          0   0          0         0   \n8     0  1     0       0    0        0          0   0          0         0   \n9     0  0     0       0    0        0          0   0          0         0   \n10    0  0     0       0    0        0          0   0          0         0   \n11    0  0     0       0    1        0          0   0          0         0   \n12    0  0     1       0    0        0          0   0          0         0   \n13    0  0     0       0    0        0          0   0          0         0   \n14    0  0     0       0    0        0          0   0          0         1   \n15    0  0     0       0    1        0          0   0          0         0   \n16    0  0     0       0    0        0          0   0          0         0   \n17    0  0     0       0    0        0          0   0          0         0   \n18    0  0     0       0    0        0          0   0          1         0   \n19    0  0     0       0    0        0          0   0          0         0   \n20    0  0     0       1    0        0          0   0          0         0   \n21    0  0     0       0    0        1          0   0          0         0   \n\n    method  of  person  the  thinks  this  through  to  using  way  \n0        0   0       0    0       0     0        0   0      0    0  \n1        0   0       0    0       0     0        0   0      0    0  \n2        0   0       0    0       0     0        0   0      0    0  \n3        1   0       0    0       0     0        0   0      0    0  \n4        0   1       0    0       0     0        0   0      0    0  \n5        0   0       0    0       0     0        0   0      0    0  \n6        0   0       0    1       0     0        0   0      0    0  \n7        0   0       0    0       0     0        0   0      0    1  \n8        0   0       0    0       0     0        0   0      0    0  \n9        0   0       1    0       0     0        0   0      0    0  \n10       0   0       0    0       1     0        0   0      0    0  \n11       0   0       0    0       0     0        0   0      0    0  \n12       0   0       0    0       0     0        0   0      0    0  \n13       0   0       0    0       0     0        1   0      0    0  \n14       0   0       0    0       0     0        0   0      0    0  \n15       0   0       0    0       0     0        0   0      0    0  \n16       0   0       0    0       0     0        0   0      1    0  \n17       0   0       0    0       0     1        0   0      0    0  \n18       0   0       0    0       0     0        0   0      0    0  \n19       0   0       0    0       0     0        0   1      0    0  \n20       0   0       0    0       0     0        0   0      0    0  \n21       0   0       0    0       0     0        0   0      0    0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NLP</th>\n      <th>a</th>\n      <th>acts</th>\n      <th>affect</th>\n      <th>and</th>\n      <th>change.</th>\n      <th>examining</th>\n      <th>is</th>\n      <th>knowledge</th>\n      <th>language</th>\n      <th>method</th>\n      <th>of</th>\n      <th>person</th>\n      <th>the</th>\n      <th>thinks</th>\n      <th>this</th>\n      <th>through</th>\n      <th>to</th>\n      <th>using</th>\n      <th>way</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(oh_vectors, columns=vocab)\n",
    "df # bear in mind the inherent zero-indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   NLP  a acts affect and change. examining is knowledge language method of  \\\n0    1                                                                        \n1                                            1                                \n2       1                                                                     \n3                                                                      1      \n4                                                                         1   \n5                                         1                                   \n6                                                                             \n7                                                                             \n8       1                                                                     \n9                                                                             \n10                                                                            \n11                      1                                                     \n12           1                                                                \n13                                                                            \n14                                                              1             \n15                      1                                                     \n16                                                                            \n17                                                                            \n18                                                     1                      \n19                                                                            \n20                  1                                                         \n21                              1                                             \n\n   person the thinks this through to using way  \n0                                               \n1                                               \n2                                               \n3                                               \n4                                               \n5                                               \n6           1                                   \n7                                            1  \n8                                               \n9       1                                       \n10                 1                            \n11                                              \n12                                              \n13                              1               \n14                                              \n15                                              \n16                                       1      \n17                      1                       \n18                                              \n19                                 1            \n20                                              \n21                                              ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NLP</th>\n      <th>a</th>\n      <th>acts</th>\n      <th>affect</th>\n      <th>and</th>\n      <th>change.</th>\n      <th>examining</th>\n      <th>is</th>\n      <th>knowledge</th>\n      <th>language</th>\n      <th>method</th>\n      <th>of</th>\n      <th>person</th>\n      <th>the</th>\n      <th>thinks</th>\n      <th>this</th>\n      <th>through</th>\n      <th>to</th>\n      <th>using</th>\n      <th>way</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df[df == 0] = ''\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 20 distinct words (columns), we can search by row and find where '1' is to locate its position in the original document\n",
    "* Hence the name 'one-hot' - given a word (vector) where '1' appears once for each row for a single token and '0' elsewhere in the vocab for that token/column pair (based on row position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End Goal:\n",
    "* Vector representation of words/documents - no information is lost, given each word is tracked/indicated by the column (vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary bag-of-words (BOW) representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example below, we can put the tokens into a binary vector BOW representation indicating the presence or absence of a particular word in a particular sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_bow = {}\n",
    "for token in sentence.split():\n",
    "    sentence_bow[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('NLP', 1),\n ('a', 1),\n ('acts', 1),\n ('affect', 1),\n ('and', 1),\n ('change.', 1),\n ('examining', 1),\n ('is', 1),\n ('knowledge', 1),\n ('language', 1),\n ('method', 1),\n ('of', 1),\n ('person', 1),\n ('the', 1),\n ('thinks', 1),\n ('this', 1),\n ('through', 1),\n ('to', 1),\n ('using', 1),\n ('way', 1)]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "sorted(sentence_bow.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these list of tuple pairs, this representation with regards to a set of sentences reveals which words were used in which document (simple index for now that show 1 revealing that this distinct word occurs in the sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           sent\nNLP           1\nis            1\na             1\nmethod        1\nof            1\nexamining     1\nthe           1\nway           1\nperson        1\nthinks        1\nand           1\nacts          1\nthrough       1\nlanguage      1\nusing         1\nthis          1\nknowledge     1\nto            1\naffect        1\nchange.       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>NLP</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>is</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>a</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>method</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>of</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>examining</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>the</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>way</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>person</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>thinks</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>and</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>acts</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>through</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>language</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>using</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>this</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>knowledge</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>to</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>affect</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>change.</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Use pandas df to make a clearer representation \n",
    "df_bow = pd.DataFrame(pd.Series(dict([(token, 1) for token in sentence.split()])), columns=['sent'])\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      NLP  is  a  method  of  examining  the  way  person  thinks  and  acts  \\\nsent    1   1  1       1   1          1    1    1       1       1    1     1   \n\n      through  language  using  this  knowledge  to  affect  change.  \nsent        1         1      1     1          1   1       1        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NLP</th>\n      <th>is</th>\n      <th>a</th>\n      <th>method</th>\n      <th>of</th>\n      <th>examining</th>\n      <th>the</th>\n      <th>way</th>\n      <th>person</th>\n      <th>thinks</th>\n      <th>and</th>\n      <th>acts</th>\n      <th>through</th>\n      <th>language</th>\n      <th>using</th>\n      <th>this</th>\n      <th>knowledge</th>\n      <th>to</th>\n      <th>affect</th>\n      <th>change.</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sent</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# Transpose this to make turn into a format similar to a matrix\n",
    "df_bow.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can add a few more texts to the corpus and identify how a DataFrame is built/extended upon in terms of **BOW vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use '\\n' as a character whereby we use to split by (new line)\n",
    "# Sentences scraped from website listed above - extended upon\n",
    "sentences = 'NLP is a method of examining the way a person thinks and acts through language and using this knowledge to affect change.\\n'\n",
    "sentences += 'NLP has techniques and strategies to help you become fully congruent.\\n'\n",
    "sentences += 'And this is the overall future direction of work in linguistics and NLP, including determiners.\\n'\n",
    "sentences += 'Obvious application areas include lexicography, natural language understanding (NLP) systems, and all branches of applied and theoretical linguistics.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'NLP is a method of examining the way a person thinks and acts through language and using this knowledge to affect change.\\nNLP has techniques and strategies to help you become fully congruent.\\nAnd this is the overall future direction of work in linguistics and NLP, including determiners.\\nObvious application areas include lexicography, natural language understanding (NLP) systems, and all branches of applied and theoretical linguistics.'"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {} \n",
    "for i, sent in enumerate(sentences.split('\\n')):\n",
    "    corpus[f'sent{i}'] = dict([(tok, 1) for tok in sent.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(corpus).fillna(0).astype(int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       NLP  is  a  method  of  examining  the  way  person  thinks\nsent0    1   1  1       1   1          1    1    1       1       1\nsent1    1   0  0       0   0          0    0    0       0       0\nsent2    0   1  0       0   1          0    1    0       0       0\nsent3    0   0  0       0   1          0    0    0       0       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NLP</th>\n      <th>is</th>\n      <th>a</th>\n      <th>method</th>\n      <th>of</th>\n      <th>examining</th>\n      <th>the</th>\n      <th>way</th>\n      <th>person</th>\n      <th>thinks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sent0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>sent1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>sent2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>sent3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "# shows first 10 tokens within the lexicon\n",
    "df[df.columns[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the dot product is very common in NLP - especially if we want to find similarity between the sentences/tokens in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,2,3])\n",
    "v2 = np.array([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "v1 @ v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 2,  6, 12])"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "v1 * v2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda572c238c43e2438fb8a17e4e11af0079",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}