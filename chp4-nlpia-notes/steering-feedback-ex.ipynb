{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600516099988",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Steering with feedback "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "All the previous approaches using LSA failed to take into account information regarding the similarity between documents. In this way, topics were created based on a generic set of rules.\n",
    "<br>\n",
    "The unsupervised learning of these feature (topic) extraction models didn't have any data about how 'close' the topic vectors should be (relative) to each other.\n",
    "<br>\n",
    "However, we did not consider any 'feedback' about where the topic vectors ended up or how they were related to each other during computation.\n",
    "<br>\n",
    "<br>\n",
    "Steering (learned distance metrics) are the latest advancements in dimension reduction and feature extraction. By adjusting the distance scores reported to clustering and embedding algorithms, we can **steer** our vectors so that they minimize some cost function. In this way we can force the vectors to focus on some aspect of the information content that we might be interested in."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In previous runs/sections of LSA (ex notebooks in repo), we ignored all of the meta information about the documents. An instance of this among SMS messages is that we ignored the sender of the message.\n",
    "<br>\n",
    "This is a good indication of topic similarity and could be used to inform your topic vector transformation (LSA)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "One method to carry out this steering computations is to calculate the mean difference between our two centroids - as was carried out for linear discriminant analysis (LDA) - and add the some portion of 'bias' to all word/topic vectors. The idea is to take out the average topic vector difference, where an example application could be such topic vector difference between CVs and job descriptions (based on a summarisation of various keywords/topics).\n",
    "<br>\n",
    "<br>\n",
    "Examples of 'steering with feedback' could mean taking into consideration that topics such as '“beer on tap at lunch' might appear in job descriptions but never in a CV. Similarly, quirky hobbies/leisure activities like underwater sculpture might appear in some CVs but never a job description.\n",
    "<br>\n",
    "Steering topic vectors can help us focus them on the topics one maybe interested in modelling.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Linear discriminant analysis (LDA)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here will be shown a LDA model trained on the labelled SMS dataset.\n",
    "<br>\n",
    "LDA works similarly to latent semnatic analysis (LSA), except it requires classification labels or other scores to be able to find the best linear combination of the dimensions in high-dimensional space (the terms in a BOW/TF-IDF vector transformation)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "import pandas as pd \n",
    "from nlpia.data.loaders import get_data\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "pd.options.display.width = 120 \n",
    "sms = get_data('sms-spam')\n",
    "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]\n",
    "sms.index = index \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).todense()\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean(axis=0) # mean of each word-vector feature (each column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(tfidf_docs, sms.spam)\n",
    "sms['lda_spaminess'] = lda.predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.0\n4837\n4837\n"
    }
   ],
   "source": [
    "# rough evaluation metrics done manually\n",
    "print(((sms.spam - sms.lda_spaminess) ** 2.).sum() ** .5)\n",
    "print((sms.spam == sms.lda_spaminess).sum())\n",
    "print(len(sms))"
   ]
  },
  {
   "source": [
    "This is a naive example of coming to a quick conclusion as saying the model got every observation on the test set correct, without considering the problems of overfitting.\n",
    "<br>\n",
    "With around 10k terms in our TF-IDF vectors, it doesn't come as a surprise that the model could just 'memorize' the answer.\n",
    "<br> \n",
    "Previous use of `train-test-split` evaluation is warranted, so let’s reserve a third of our dataset for testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.764"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_docs, sms.spam, test_size=0.33, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda.fit(X_train, y_train)\n",
    "lda.score(X_test, y_test).round(3)"
   ]
  },
  {
   "source": [
    "Again, poor test set accuracy. So it doesn’t look like we're unlucky with our data sampling. It’s a poor, overfitting model.\n",
    "<br>\n",
    "Let’s see if LSA combined with LDA will help us create an accurate model that is also generalized well so that new SMS messages don’t trip it up:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  topic9  topic10  topic11  topic12  \\\nsms0    0.201   0.003   0.037   0.011  -0.019  -0.053   0.039  -0.065   0.011  -0.082    0.008    0.000    0.003   \nsms1    0.404  -0.094  -0.078   0.051   0.100   0.047   0.023   0.066   0.022  -0.022   -0.005   -0.036    0.040   \nsms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.043  -0.000   0.000  -0.058   0.054    0.127   -0.031    0.017   \nsms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  -0.165  -0.073   0.062  -0.106    0.022   -0.021    0.077   \nsms4    0.002   0.031   0.038   0.034  -0.075  -0.093  -0.044   0.061  -0.044   0.030    0.027    0.014    0.026   \nsms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040   0.005   0.165  -0.022   0.063    0.041   -0.052   -0.041   \n\n       topic13  topic14  topic15  \nsms0    -0.031   -0.004    0.027  \nsms1    -0.016    0.051   -0.050  \nsms2!   -0.004   -0.035    0.048  \nsms3    -0.043    0.012   -0.063  \nsms4     0.031   -0.075   -0.019  \nsms5!    0.070   -0.004    0.023  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n      <th>topic14</th>\n      <th>topic15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sms0</th>\n      <td>0.201</td>\n      <td>0.003</td>\n      <td>0.037</td>\n      <td>0.011</td>\n      <td>-0.019</td>\n      <td>-0.053</td>\n      <td>0.039</td>\n      <td>-0.065</td>\n      <td>0.011</td>\n      <td>-0.082</td>\n      <td>0.008</td>\n      <td>0.000</td>\n      <td>0.003</td>\n      <td>-0.031</td>\n      <td>-0.004</td>\n      <td>0.027</td>\n    </tr>\n    <tr>\n      <th>sms1</th>\n      <td>0.404</td>\n      <td>-0.094</td>\n      <td>-0.078</td>\n      <td>0.051</td>\n      <td>0.100</td>\n      <td>0.047</td>\n      <td>0.023</td>\n      <td>0.066</td>\n      <td>0.022</td>\n      <td>-0.022</td>\n      <td>-0.005</td>\n      <td>-0.036</td>\n      <td>0.040</td>\n      <td>-0.016</td>\n      <td>0.051</td>\n      <td>-0.050</td>\n    </tr>\n    <tr>\n      <th>sms2!</th>\n      <td>-0.030</td>\n      <td>-0.048</td>\n      <td>0.090</td>\n      <td>-0.067</td>\n      <td>0.091</td>\n      <td>-0.043</td>\n      <td>-0.000</td>\n      <td>0.000</td>\n      <td>-0.058</td>\n      <td>0.054</td>\n      <td>0.127</td>\n      <td>-0.031</td>\n      <td>0.017</td>\n      <td>-0.004</td>\n      <td>-0.035</td>\n      <td>0.048</td>\n    </tr>\n    <tr>\n      <th>sms3</th>\n      <td>0.329</td>\n      <td>-0.033</td>\n      <td>-0.035</td>\n      <td>-0.016</td>\n      <td>0.052</td>\n      <td>0.056</td>\n      <td>-0.165</td>\n      <td>-0.073</td>\n      <td>0.062</td>\n      <td>-0.106</td>\n      <td>0.022</td>\n      <td>-0.021</td>\n      <td>0.077</td>\n      <td>-0.043</td>\n      <td>0.012</td>\n      <td>-0.063</td>\n    </tr>\n    <tr>\n      <th>sms4</th>\n      <td>0.002</td>\n      <td>0.031</td>\n      <td>0.038</td>\n      <td>0.034</td>\n      <td>-0.075</td>\n      <td>-0.093</td>\n      <td>-0.044</td>\n      <td>0.061</td>\n      <td>-0.044</td>\n      <td>0.030</td>\n      <td>0.027</td>\n      <td>0.014</td>\n      <td>0.026</td>\n      <td>0.031</td>\n      <td>-0.075</td>\n      <td>-0.019</td>\n    </tr>\n    <tr>\n      <th>sms5!</th>\n      <td>-0.016</td>\n      <td>0.059</td>\n      <td>0.014</td>\n      <td>-0.006</td>\n      <td>0.122</td>\n      <td>-0.040</td>\n      <td>0.005</td>\n      <td>0.165</td>\n      <td>-0.022</td>\n      <td>0.063</td>\n      <td>0.041</td>\n      <td>-0.052</td>\n      <td>-0.041</td>\n      <td>0.070</td>\n      <td>-0.004</td>\n      <td>0.023</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# 16-D topic vectors \n",
    "pca = PCA(n_components=16)\n",
    "# saves us one more step performing fit_transform simultaneously on training set \n",
    "pca_topic_vectors16 = pca.fit_transform(tfidf_docs)\n",
    "columns = [f'topic{i}' for i in range(pca.n_components_)]\n",
    "pca_topic_vectors_df = pd.DataFrame(pca_topic_vectors16, columns=columns, index=sms.index)\n",
    "pca_topic_vectors_df.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.965"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pca_topic_vectors_df.to_numpy(), sms.spam, test_size=0.3, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda.fit(X_train, y_train)\n",
    "lda.score(X_test, y_test).round(3)"
   ]
  },
  {
   "source": [
    "***Summary***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "So with LSA, we can characterise properties of an SMS message with only 16 dimensions and still have plenty of information to classify them as spam (or not).\n",
    "<br>\n",
    "Also, our low-dimensional model is much less likely to overfit. It should generalise well and be able to classify as-yet-unseen SMS messages or chats.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We got better accuracy with your simple LDA model before trying all the semantic analysis approaches. But the advantage of this new model (LDA + LSA/PCA) is that we can create vectors that represent the semantics of a statement in more than just a single dimension."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}